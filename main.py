# import lib
import os
import time
import re
import openai
import streamlit as st
from dotenv import load_dotenv
from pinecone import Pinecone
from langchain_pinecone import PineconeVectorStore
from langchain_community.embeddings.openai import OpenAIEmbeddings
from openai import AsyncOpenAI
import asyncio
from streamlit_star_rating import st_star_rating
import yaml
import pandas as pd
import matplotlib.pyplot as plt
load_dotenv()

PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')
pc = Pinecone(api_key=PINECONE_API_KEY)

index_name = 'llm-chatbot-gpt'
embedding = None
client = None
pVS = None


primer2 = f"""B√¢y gi·ªù b·∫°n h√£y ƒë√≥ng vai tr√≤ l√† m·ªôt lu·∫≠t s∆∞ xu·∫•t s·∫Øc v·ªÅ lu·∫≠t h√¥n nh√¢n v√† gia ƒë√¨nh ·ªü Vi·ªát Nam.
T√¥i s·∫Ω h·ªèi b·∫°n c√°c c√¢u h·ªèi v·ªÅ t√¨nh hu·ªëng th·ª±c t·∫ø li√™n quan t·ªõi lu·∫≠t h√¥n nh√¢n v√† gia ƒë√¨nh. B·∫°n h√£y t√≥m t·∫Øt t√¨nh hu·ªëng
v√† ƒë∆∞a ra c√°c c√¢u h·ªèi ng·∫Øn g·ªçn g·ªìm t·ª´ kho√° li√™n quan t·ªõi ph√°p lu·∫≠t ƒë∆∞·ª£c suy lu·∫≠n t·ª´ ph·∫ßn th√¥ng tin c√≥ trong t√¨nh hu·ªëng. C√°c c√¢u tr·∫£ l·ªùi c·ªßa b·∫°n
ƒë·ªÅu l√† ti·∫øng vi·ªát.

Sau ƒë√¢y l√† m·ªôt s·ªë v√≠ d·ª• v√† ph·∫ßn t√≥m t·∫Øt:
1. T√¨nh hu·ªëng: Bi·∫øt m√¨nh ƒë·ªß tu·ªïi k·∫øt h√¥n v√† ƒë√°p ·ª©ng c√°c ƒëi·ªÅu ki·ªán k·∫øt h√¥n, Anh S v√† ch·ªã Y d·ª± ƒë·ªãnh ƒëi ƒëƒÉng k√Ω k·∫øt h√¥n tr∆∞·ªõc khi t·ªï ch·ª©c l·ªÖ c∆∞·ªõi 02 th√°ng. Ch·ªã Y v√† anh S c√≥ h·ªô kh·∫©u th∆∞·ªùng tr√∫ ·ªü hai t·ªânh kh√°c nhau, anh ch·ªã mu·ªën bi·∫øt vi·ªác ƒëƒÉng k√Ω k·∫øt h√¥n th·ª±c hi·ªán t·∫°i c∆° quan n√†o v√† c·∫ßn th·ª±c hi·ªán th·ªß t·ª•c g√¨?
-> T√≥m t·∫Øt: Th·ªß t·ª•c ƒëƒÉng k√Ω k·∫øt h√¥n l√† g√¨, h·ªô kh·∫©u th∆∞·ªùng tr√∫ trong th·ªß t·ª•c k·∫øt h√¥n

2. √îng b√† B c√≥ con trai ƒë√£ 25 tu·ªïi, b·ªã b·ªánh ƒëao b·∫©m sinh. V√¨ mu·ªën l·∫•y v·ª£ cho con trai, b√† B ƒë√£ t√¨m c√°ch vu c√°o cho ch·ªã Y ‚Äì ng∆∞·ªùi gi√∫p vi·ªác l·∫•y tr·ªôm s·ªë ti·ªÅn 1.000.000 ƒë·ªìng. B√† B  ƒëe d·ªça n·∫øu ch·ªã Y kh√¥ng mu·ªën b·ªã b√°o c√¥ng an, kh√¥ng mu·ªën b·ªã ƒëi t√π th√¨ ph·∫£i l·∫•y con trai b√†, v·ª´a ƒë∆∞·ª£c l√†m ch·ªß nh√†, kh√¥ng ph·∫£i l√†m ng∆∞·ªùi gi√∫p vi·ªác l·∫°i c√≥ cu·ªôc s·ªëng sung t√∫c. V√¨ nh·∫≠n th·ª©c h·∫°n ch·∫ø, tr√¨nh ƒë·ªô vƒÉn h√≥a th·∫•p n√™n ch·ªã Y ƒë√£ ƒë·ªìng √Ω l·∫•y con trai b√† B. H√¥n l·ªÖ ch·ªâ t·ªï ch·ª©c gi·ªØa hai gia ƒë√¨nh m√† kh√¥ng l√†m th·ªß t·ª•c ƒëƒÉng k√Ω k·∫øt h√¥n t·∫°i ph∆∞·ªùng. Vi·ªác l√†m c·ªßa b√† B c√≥ vi ph·∫°m ph√°p lu·∫≠t kh√¥ng? N·∫øu c√≥ th√¨ b·ªã x·ª≠ ph·∫°t nh∆∞ th·∫ø n√†o?
-> T√≥m t·∫Øt: c∆∞·ª°ng √©p k·∫øt h√¥n c√≥ b·ªã x·ª≠ ph·∫°t kh√¥ng, c∆∞·ª°ng √©p k·∫øt h√¥n b·ªã x·ª≠ ph·∫°t nh∆∞ th·∫ø n√†o 

3. T√¥i ƒë√£ k·∫øt h√¥n ƒë∆∞·ª£c 6 th√°ng, nh∆∞ng ch∆∞a chuy·ªÉn h·ªô kh·∫©u v·ªÅ nh√† ch·ªìng (·ªü x√£ X, huy·ªán B, t·ªânh A), h·ªô kh·∫©u c·ªßa t√¥i v·∫´n ƒëang ·ªü nh√† b·ªë m·∫π ƒë·∫ª (x√£ Y, huy·ªán C, t·ªânh D). Nay t√¥i c√≥ nguy·ªán v·ªçng chuy·ªÉn h·ªô kh·∫©u v·ªÅ nh√† ch·ªìng th√¨ c√≥ ƒë∆∞·ª£c kh√¥ng v√† th·ªß t·ª•c th·ª±c hi·ªán nh∆∞ th·∫ø n√†o? Ai c√≥ th·∫©m quy·ªÅn gi·∫£i quy·∫øt?
-> t√≥m t·∫Øt: c√≥ ƒë∆∞·ª£c chuy·ªÉn h·ªô kh·∫©u v·ªÅ nh√† ch·ªìng kh√¥ng, Th·ªß t·ª•c chuy·ªÉn h·ªô kh·∫©u, Ai gi·∫£i quy·∫øt th·ªß t·ª•c chuy·ªÉn h·ªô kh·∫©u
"""

primer1 = f"""B√¢y gi·ªù b·∫°n h√£y ƒë√≥ng vai tr√≤ l√† m·ªôt lu·∫≠t s∆∞ xu·∫•t s·∫Øc v·ªÅ lu·∫≠t h√¥n nh√¢n v√† gia ƒë√¨nh ·ªü Vi·ªát Nam.
T√¥i s·∫Ω h·ªèi b·∫°n c√°c c√¢u h·ªèi v·ªÅ t√¨nh hu·ªëng th·ª±c t·∫ø li√™n quan t·ªõi lu·∫≠t h√¥n nh√¢n v√† gia ƒë√¨nh. B·∫°n s·∫Ω tr·∫£ l·ªùi c√¢u h·ªèi
d·ª±a tr√™n th√¥ng tin t√¥i cung c·∫•p v√† th√¥ng tin c√≥ trong c√¢u h·ªèi. N·∫øu th√¥ng tin t√¥i cung c·∫•p kh√¥ng ƒë·ªß ƒë·ªÉ tr·∫£ l·ªùi
h√£y n√≥i r·∫±ng 'T√¥i kh√¥ng bi·∫øt'. C√°c c√¢u tr·∫£ l·ªùi c·ªßa b·∫°n ƒë·ªÅu l√† ti·∫øng vi·ªát. 
L∆∞u √Ω: N√™u r√µ ƒëi·ªÅu lu·∫≠t s·ªë m·∫•y ƒë·ªÉ tr·∫£ l·ªùi t√¨nh hu·ªëng.
"""

def check_string(s):
    pattern = r"N·∫øu b·∫°n c·∫ßn"
    match = re.search(pattern, s)
    if match:
        return True
    else:
        return False

def remove_string(s):
    pattern = r"N·∫øu b·∫°n c·∫ßn .*"
    return re.sub(pattern, "", s)

async def qa1(prompt):

    response = await client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": primer1},
            {"role": "user", "content": prompt}
        ]
    )
    msg = response.choices[0].message.content
    return str(msg)

async def qa2(prompt):
    context = ""
    if len(prompt) <= 150:
        relevant_docs = pVS.similarity_search(query=prompt, k=1)
        context += relevant_docs[0].page_content
    else:
        chats = await client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": primer2},
                {"role": "user", "content": prompt}
            ]
        )

        new_query = chats.choices[0].message.content
        context = ""

        texts = new_query.split(',')

        for text in texts:
            # print(text)
            relevant_docs = pVS.similarity_search(query=text, k=1)

            context += relevant_docs[0].page_content

        relevant_docs = pVS.similarity_search(query=prompt, k=1)
        context += relevant_docs[0].page_content
    context += "\n" + prompt

    response = await client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": primer1},
            {"role": "user", "content": context}
        ]
    )
    msg = response.choices[0].message.content
    if check_string(msg):
        msg = remove_string(msg)
    return str(msg)

async def page_1():
    global embedding
    global client
    global pVS

    embedding = OpenAIEmbeddings(openai_api_key = st.session_state.openai_apikey)

    client = AsyncOpenAI(api_key= st.session_state.openai_apikey)

    pVS = PineconeVectorStore(
        index_name=index_name,
        embedding=embedding
    )

    st.title("üßë‚Äçüíªüí¨ A RAG chatbot for family and marriage legal questions")
    """
    ƒê√¢y l√† chatbot gi√∫p ng∆∞·ªùi d√¢n t√¨m hi·ªÉu lu·∫≠t h√¥n nh√¢n v√† gia ƒë√¨nh. B·∫°n h√£y h·ªèi nh·ªØng c√¢u h·ªèi c√≥ li√™n quan t·ªõi lu·∫≠t n√†y nh√©.
    """

    for conversation in st.session_state.chat_history:
        st.chat_message("user").write(conversation['question'])
        col1, col2 = st.columns(2)
        with col1:
            st.chat_message("assisstant").write(conversation['answer1'])
        with col2:
            st.chat_message("assisstant").write(conversation['answer2'])
        st.write("N·∫øu c·∫ßn t∆∞ v·∫•n r√µ h∆°n, b·∫°n c√≥ th·ªÉ li√™n h·ªá lu·∫≠t s∆∞ qua trang web [Lu·∫≠t minh khu√™](https://luatminhkhue.vn/)")
        st.write(f"You rated this answer {conversation['stars']} :star:")
    if "stars" not in st.session_state:
        st.session_state.stars = ""

    if st.session_state.stars:
        st.session_state.chat_history.append(
            {'question': st.session_state['question'],
             'answer1': st.session_state['msg1'],
             'answer2': st.session_state['msg2'],
             'stars': st.session_state['stars']
             }
        )
        df = pd.read_csv('./result.csv')
        new_row = {
            'question': st.session_state['question'],
            'gpt_answer': st.session_state['msg1'],
            'enhanced_answer': st.session_state['msg2'],
            'rating': st.session_state['stars']
        }
        df = df._append(new_row,ignore_index=True)
        df.to_csv('./result.csv', index=False)
        st.chat_message("user").write(st.session_state['question'])
        col1, col2 = st.columns(2)
        with col1:
            st.chat_message("assisstant").write(st.session_state['msg1'])
        with col2:
            st.chat_message("assisstant").write(st.session_state['msg2'])
        st.write("N·∫øu c·∫ßn t∆∞ v·∫•n r√µ h∆°n, b·∫°n c√≥ th·ªÉ li√™n h·ªá lu·∫≠t s∆∞ qua trang web [Lu·∫≠t minh khu√™](https://luatminhkhue.vn/)")
        st.write(f"You rated this answer {st.session_state['stars']} :star:")
        del st.session_state.prompt
    if prompt := st.chat_input():
        st.session_state.prompt = prompt
        st.chat_message("user").write(prompt)
        msg1 = await qa1(prompt)
        msg2 = await qa2(prompt)

        col1, col2 = st.columns(2)
        with col1:
            st.chat_message("assisstant").write(msg1)
        with col2:
            st.chat_message("assisstant").write(msg2)
        st.write("N·∫øu c·∫ßn t∆∞ v·∫•n r√µ h∆°n, b·∫°n c√≥ th·ªÉ li√™n h·ªá lu·∫≠t s∆∞ qua trang web [Lu·∫≠t minh khu√™](https://luatminhkhue.vn/)")
        st.session_state.question = prompt
        st.session_state.msg1 = msg1
        st.session_state.msg2 = msg2

    if "prompt" in st.session_state:
        stars = st_star_rating("Please rate you experience", maxValue=4, defaultValue=3, key="stars")

async def page_2():
    # T·∫°o m·∫´u DataFrame v·ªõi 4 c·ªôt
    df = pd.read_csv('./result.csv')

    # Hi·ªÉn th·ªã DataFrame trong Streamlit
    st.write("Data:")
    st.write(df)
    st.write(f"There is total of {len(df)} answered questons")
    # Visualize c·ªôt "score" b·∫±ng Matplotlib trong Streamlit
    st.write("Histogram of 'rating' column:")
    fig, ax = plt.subplots()
    ax.hist(df['rating'], bins=4)
    ax.set_xlabel('Rating')
    ax.set_ylabel('Count')

    # Ch·ªâ hi·ªÉn th·ªã c√°c gi√° tr·ªã 1, 2, 3, 4 tr√™n tr·ª•c x
    ax.set_xticks([1, 2, 3, 4])
    ax.set_xticklabels(['1', '2', '3', '4'])

    # Hi·ªÉn th·ªã gi√° tr·ªã c·ªßa t·ª´ng c·ªôt trong histogram
    for i, count in enumerate(ax.patches):
        ax.annotate(str(int(count.get_height())),
                    xy=(count.get_x() + count.get_width() / 2, count.get_height()),
                    ha='center', va='bottom')

    st.pyplot(fig)


def page_3():
    # Giao di·ªán nh·∫≠p API key
    st.title("Nh·∫≠p API Key")
    api_key_input = st.text_input("API Key:", type="password")
    st.session_state.openai_apikey = api_key_input
    # N√∫t ƒë·ªÉ l∆∞u API key
    if st.button("L∆∞u API Key"):
        st.success("API Key ƒë√£ ƒë∆∞·ª£c l∆∞u!")


PAGES = {
    "Chat": page_1,
    "Statistic": page_2,
    "Update API KEY": page_3
}

def main():
    st.set_page_config(page_title="RAG Chatbot")
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    if "openai_apikey" not in st.session_state:
        st.session_state.openai_apikey = os.getenv('OPENAI_API_KEY')
    # asyncio.run(question_answering())

    st.sidebar.title("Navigation")
    choice = st.sidebar.selectbox("Select an option", list(PAGES.keys()))
    # Call the page function
    if choice != "Update API KEY":
        asyncio.run(PAGES[choice]())
    else:
        PAGES[choice]()

if __name__ == "__main__":
    main()


